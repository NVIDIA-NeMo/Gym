# SWE-bench wrapper configuration for SWE-agent
swe_agents:
  responses_api_agents:
    swe_agents:
      entrypoint: app.py
      
      # Agent framework configuration
      agent_framework: swe_agent
      agent_config: eval/swe-bench/swe-agent/default_one_tool
      agent_max_turns: 100
      agent_tools_file: configs/swe_agent_tools_openai_format.json
      
      # Container configuration
      container_formatter: "docker://swebench/sweb.eval.x86_64.{instance_id}"
      container_folder_path: null
      swebench_tests_timeout: 1800  # 30 minutes
      
      # Optional model server reference
      model_server:
        name: policy_model # openai_model
        type: responses_api_models
      
      # Additional NeMo-Skills configuration
      nemo_skills_config:
        max_samples: -1
        skip_filled: false
        dry_run: false
        max_concurrent_requests: 1  # SWE-bench is resource intensive
      
      # Dataset configurations
      datasets:
        # Training dataset
        - name: train
          type: train
          jsonl_fpath: responses_api_agents/swe_agents/data/swegym_for_sweagent_and_openhands.jsonl
          gitlab_identifier:
            dataset_name: swegym_for_sweagent_and_openhands
            version: 0.0.1
            artifact_fpath: swegym_for_sweagent_and_openhands.jsonl
          license: MIT
        
        # Validation dataset  
        - name: validation
          type: validation
          jsonl_fpath: responses_api_agents/swe_agents/data/swebench_verified_for_sweagent_and_openhands.jsonl
          gitlab_identifier:
            dataset_name: swebench_verified_for_sweagent_and_openhands
            version: 0.0.1
            artifact_fpath: swebench_verified_for_sweagent_and_openhands.jsonl
          license: TBD
        
        # Example dataset for quick testing
        - name: example
          type: example
          jsonl_fpath: responses_api_agents/swe_agents/data/example.jsonl
  