from typing import List, Union, NotRequired, Required, Literal, Optional

from pydantic import BaseModel

from openai import AsyncOpenAI
from openai.types.responses.response_create_params import (
    ResponseCreateParamsNonStreaming,
    ToolParam,
)
from openai.types.shared.chat_model import ChatModel
from openai.types.chat.completion_create_params import (
    CompletionCreateParamsNonStreaming,
    ChatCompletionMessageParam,
)
from openai.types.chat import ChatCompletion
from openai.types.responses import Response, ResponseOutputItem

from nemo_gym.server_utils import GLOBAL_HTTPX_CLIENT


class NeMoGymResponseCreateParamsNonStreaming(ResponseCreateParamsNonStreaming):
    # Override the Iterable to avoid lazy iterators in Pydantic validation.
    tools: NotRequired[List[ToolParam]]


class NeMoGymFunctionCallOutput(BaseModel):
    """
    We copy openai.types.responses.response_input_param.FunctionCallOutput, originally a TypedDict, as a BaseModel here
    so that we can use it in the NeMoGymResponseOutputItem below and be consistent with the other ResponseOutputItem types.
    """

    call_id: str
    """The unique ID of the function tool call generated by the model."""

    output: str
    """A JSON string of the output of the function tool call."""

    type: Literal["function_call_output"]
    """The type of the function tool call output. Always `function_call_output`."""

    id: Optional[str] = None
    """The unique ID of the function tool call output.

    Populated when this item is returned via API.
    """

    status: Optional[Literal["in_progress", "completed", "incomplete"]] = None
    """The status of the item.

    One of `in_progress`, `completed`, or `incomplete`. Populated when items are
    returned via API.
    """


NeMoGymResponseOutputItem = Union[NeMoGymFunctionCallOutput, ResponseOutputItem]


class NeMoGymResponse(Response):
    output: List[NeMoGymResponseOutputItem]


class NeMoGymChatCompletionCreateParamsNonStreaming(
    CompletionCreateParamsNonStreaming, total=False
):
    messages: Required[List[ChatCompletionMessageParam]]
    model: NotRequired[Union[str, ChatModel]]


class NeMoGymChatCompletionResponse(ChatCompletion):
    pass


class NeMoGymAsyncOpenAI(AsyncOpenAI):
    def __init__(self, **kwargs) -> None:
        # TODO: this setup is take from https://github.com/NVIDIA/NeMo-Skills/blob/80dc78ac758c4cac81c83a43a729e7ca1280857b/nemo_skills/inference/model/base.py#L318
        # However, there may still be a lingering issue regarding saturating at 100 max connections
        kwargs["http_client"] = GLOBAL_HTTPX_CLIENT
        kwargs["timeout"] = None  # Enforce no timeout

        super().__init__(**kwargs)
