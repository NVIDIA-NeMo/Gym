(training-integration-nemo-rl-dpo)=

# DPO Training Guide

Train with **Direct Preference Optimization** using preference pairs.

**Best for**: Quality tuning, style preferences, safety

---

:::{note}
This guide is under development. For now, refer to the {doc}`index` for an overview of NeMo RL integration patterns and {ref}`training-rollout-sampling-dpo` for data preparation guidance.
:::

## Overview

DPO (Direct Preference Optimization) learns from preference pairs:

- Compares multiple rollouts for the same prompt
- Learns quality distinctions and preferences
- Best for teaching style, safety, and quality
- Requires paired comparison data

## Quick Start

Coming soon.

## Related Resources

- {doc}`index` - NeMo RL Integration Overview
- {ref}`training-rollout-sampling-dpo` - DPO Data Preparation
- {doc}`advanced` - Advanced Integration Patterns
- {ref}`training-rollout-collection` - Rollout Collection Guide

