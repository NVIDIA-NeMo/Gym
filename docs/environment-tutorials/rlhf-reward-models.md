(env-rlhf-reward-models)=
# RLHF with Reward Models

```{warning}
This article has not been reviewed by a developer SME. Content may change.
```

```{note}
This tutorial is planned but not yet implemented. The content below describes the intended scope.
```

Integrate learned reward models for Reinforcement Learning from Human Feedback (RLHF).

---

## Planned Scope

This tutorial will cover:

- Using learned reward models for verification
- Integrating Hugging Face reward models
- Combining rule-based and model-based rewards

## Current Alternatives

For model-based verification patterns available today, see:

- {doc}`llm-as-judge` — LLM-based answer verification
- `resources_servers/math_with_judge/` — Hybrid rule-based + LLM verification

## Related Resources

- {ref}`training-nemo-rl-grpo-index` — Training with NeMo RL
