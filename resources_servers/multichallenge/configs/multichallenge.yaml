# MultiChallenge Environment
# Evaluates model responses on the MultiChallenge benchmark using an LLM judge.
# Each task contains a conversation context and a rubric of yes/no questions.

# ============================================================================
# Configurable splits: "advanced", "vanilla", or custom paths
# ============================================================================

multichallenge:
  resources_servers:
    multichallenge:
      entrypoint: app.py
      
      # Judge model configuration
      judge_model_server:
        type: responses_api_models
        name: policy_model
      
      # Parameters for judge requests
      judge_responses_create_params:
        input: []
        max_output_tokens: 512
        temperature: 0.0
      
      # Aggregation mode: mean | min | max | all | any | weighted
      aggregation_mode: mean
      parallel_evaluation: true
      
      # Judge system message
      judge_system_message: "You are a precise evaluator. Assess responses objectively based on the given criteria."
      
      # Judge prompt template with placeholders
      judge_prompt_template: |-
        You are evaluating whether a model's response meets a specific criterion.

        CONVERSATION CONTEXT:
        {context}

        MODEL'S FINAL RESPONSE:
        {response}

        EVALUATION QUESTION:
        {question}

        EXPECTED ANSWER: {pass_criteria}

        Does the model's response satisfy the criterion described in the evaluation question?
        Analyze carefully, then respond with exactly [[YES]] or [[NO]] on the last line.
      
      # Verdict labels
      yes_label: "[[YES]]"
      no_label: "[[NO]]"
      
      domain: knowledge
      description: "MultiChallenge benchmark evaluation with LLM judge"

# Agent configuration using the simple_agent
multichallenge_simple_agent:
  responses_api_agents:
    simple_agent:
      entrypoint: app.py
      resources_server:
        type: resources_servers
        name: multichallenge
      model_server:
        type: responses_api_models
        name: policy_model
      datasets:
        - name: multichallenge_example
          type: example
          license: "Apache 2.0"
          jsonl_fpath: resources_servers/multichallenge/data/example.jsonl
        - name: multichallenge_advanced
          type: train
          license: "TBD"
          jsonl_fpath: resources_servers/multichallenge/data/advanced.jsonl
        - name: multichallenge_vanilla
          type: train
          license: "TBD"
          jsonl_fpath: resources_servers/multichallenge/data/vanilla.jsonl
