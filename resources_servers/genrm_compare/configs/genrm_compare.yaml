# GenRM Pairwise Comparison Resources Server Config
#
# This server compares multiple candidate responses using a GenRM model.
# The GenRM model uses a special chat template with roles 'response_1' and 'response_2'.
#
# Expected GenRM output format (JSON):
# {
#     "score_1": <1-5>,  # Individual helpfulness score for response 1
#     "score_2": <1-5>,  # Individual helpfulness score for response 2
#     "ranking": <1-6>   # 1=R1 much better, 6=R2 much better
# }

genrm_compare:
  resources_servers:
    genrm_compare:
      entrypoint: app.py
      
      # GenRM model server reference
      # KEY CHANGE FROM PR #523: Points to genrm_model (not vllm_model)
      genrm_model_server:
        type: responses_api_models
        name: genrm_model  # This is our new GenRMModel
      
      # Generation params for GenRM calls
      genrm_responses_create_params:
        input: []
        max_output_tokens: 16384
        temperature: 0.6
        top_p: 0.95
      
      # Comparison strategy: "all_pairs" (C(n,2) comparisons) or "circular" (n comparisons)
      comparison_strategy: circular
      
      # Number of judge passes per pair (for majority voting)
      num_judges_per_comparison: 1
      
      # Principle-based comparison
      use_principle: false
      # default_principle: "..." (see code for full default text)
      
      # Aggregator method (only "simple_tiebreaker" is currently supported)
      aggregator_method: simple_tiebreaker
      
      # Bonus for shortest reasoning trace if in top percentile
      reasoning_bonus: 0.0
      # Bonus for shortest final answer if in top percentile
      answer_bonus: 0.0
      # Top percentile threshold (e.g., 0.2 = top 20%)
      top_percentile: 0.2
      # Group-relative length penalty coefficients
      # Shorter responses get bonus, longer get penalty (mean-centered)
      group_reasoning_length_penalty_coeff: 0.0
      group_answer_length_penalty_coeff: 0.0
      
      # Default scores when parsing fails
      default_score: 3.0
      default_ranking: 3.5
      
      # Debug logging
      debug_logging: false
      
      # Parse retry configuration
      genrm_parse_retries: 3
      genrm_parse_retry_sleep_s: 0.2
      
      # Server metadata
      domain: rlhf
      verified: false
      description: GenRM pairwise comparison for RLHF training
      value: Compare multiple candidate responses using GenRM model
