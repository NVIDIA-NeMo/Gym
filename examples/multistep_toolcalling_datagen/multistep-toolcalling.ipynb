{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Building Multi-Step Tool-Calling Datasets with Data Designer\n",
    "\n",
    "Generate synthetic training data for agentic Reinforcement-Learning using NVIDIA **Data Designer** to enhance multi-step tool calling ability.\n",
    "\n",
    "## Prerequisites\n",
    "\n",
    "- **NVIDIA API Key** from [build.nvidia.com](https://build.nvidia.com) to access a remote LLM for generation. Alternatively, you may choose to use your own endpoint or deployment.\n",
    "- **Python 3.11+**\n",
    "- **Tool definition files** in the `tools/` directory (included in this repo)\n",
    "- Packages: `data-designer`, `pydantic`, `pandas`\n",
    "\n",
    "## Objectives\n",
    "\n",
    "By the end of this notebook, you will:\n",
    "\n",
    "- Load known **tool schemas** as the seed for generating agent queries and simulated trajectories\n",
    "- Use **Data Designer** to generate realistic multi-step user queries\n",
    "- Simulate **agent trajectories** (step-by-step tool-call solutions)\n",
    "- Apply **dual-level LLM judge filtering** to ensure data quality\n",
    "- Export training data in **NeMo Gym format** for rollout collection and RLVR training\n",
    "\n",
    "# \n",
    "#\n",
    "> **Context Note:** The primary goal of this notebook is user query generation. The trajectory generation step in this notebook serves as a sanity check to ensure the generated query leads to a feasible path. In production RL training, rollout (oracle trajectory) traces are generated from the environment itself. You may find more information in [NeMo Gym Rollout Collection](https://docs.nvidia.com/nemo/gym/latest/get-started/rollout-collection.html) documentation."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Architecture Overview\n",
    "\n",
    "```\n",
    " ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê\n",
    " ‚îÇ                  DATA GENERATION PIPELINE                     ‚îÇ\n",
    " ‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§\n",
    " ‚îÇ                                                               ‚îÇ\n",
    " ‚îÇ   ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê    ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê    ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê    ‚îÇ\n",
    " ‚îÇ   ‚îÇ Tool Schemas ‚îÇ‚îÄ‚îÄ‚îÄ‚ñ∂‚îÇ  User Query  ‚îÇ‚îÄ‚îÄ‚îÄ‚ñ∂‚îÇ  Trajectory  ‚îÇ    ‚îÇ\n",
    " ‚îÇ   ‚îÇ    (Seed)    ‚îÇ    ‚îÇ Generation   ‚îÇ    ‚îÇ Simulation   ‚îÇ    ‚îÇ\n",
    " ‚îÇ   ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò    ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò    ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò    ‚îÇ\n",
    " ‚îÇ                                                  ‚îÇ            ‚îÇ\n",
    " ‚îÇ                                                  ‚ñº            ‚îÇ\n",
    " ‚îÇ                                           ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê    ‚îÇ\n",
    " ‚îÇ                                           ‚îÇ  LLM Judge   ‚îÇ    ‚îÇ\n",
    " ‚îÇ                                           ‚îÇ  (Quality)   ‚îÇ    ‚îÇ\n",
    " ‚îÇ                                           ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò    ‚îÇ\n",
    " ‚îÇ                                                  ‚îÇ            ‚îÇ\n",
    " ‚îÇ                                                  ‚ñº            ‚îÇ\n",
    " ‚îÇ                                           ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê    ‚îÇ\n",
    " ‚îÇ                                           ‚îÇ  NeMo Gym    ‚îÇ    ‚îÇ\n",
    " ‚îÇ                                           ‚îÇ   Format     ‚îÇ    ‚îÇ\n",
    " ‚îÇ                                           ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò    ‚îÇ\n",
    " ‚îÇ                                                               ‚îÇ\n",
    " ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 1: Install and Import Dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install -q data-designer pydantic pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import random\n",
    "from typing import List, Optional\n",
    "from pydantic import BaseModel, Field\n",
    "import pandas as pd\n",
    "\n",
    "# Data Designer imports\n",
    "from data_designer.config import (\n",
    "    ChatCompletionInferenceParams,\n",
    "    DataDesignerConfigBuilder,\n",
    "    LLMStructuredColumnConfig,\n",
    "    LLMTextColumnConfig,\n",
    "    LocalFileSeedSource,\n",
    "    ModelConfig,\n",
    "    SamplingStrategy,\n",
    "    ModelProvider,\n",
    ")\n",
    "from data_designer.interface import DataDesigner"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Context: What is the Workplace Assistant Environment?\n",
    "\n",
    "[**Workplace Assistant**](https://docs.nvidia.com/nemo/gym/latest/tutorials/nemo-rl-grpo/about-workplace-assistant.html#) is a multi-step tool-using benchmark environment used in **NeMo Gym** for RL training. A model gets a natural language business request and must call tools in the right order with valid arguments (up to 6 steps).\n",
    "\n",
    "At a high level:\n",
    "- The model reads a user request (for example, scheduling meetings or updating CRM records)\n",
    "- The model decides which tools to call and with what parameters\n",
    "- The environment verifies correctness using **state matching** (final database state), not exact step matching\n",
    "\n",
    "In this notebook, we focus on **data generation**: starting from known tool schemas, generating realistic user requests, and simulating feasible trajectories to produce NeMo Gym-compatible training data.\n",
    "\n",
    "> **Note:** The official NeMo Gym [Workplace Assistant environment](https://github.com/NVIDIA-NeMo/Gym/tree/main/resources_servers/workplace_assistant) is the training target. This notebook is an example synthetic data preparation stage that feeds that workflow."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 2: Load Tool Definitions\n",
    "\n",
    "This notebook begins with **established tool schemas** and leverages them as foundational context for data generation. These schemas represent the (possibly domain-specific) tools on which you aim to enhance model performance.\n",
    "\n",
    "We use 27 tools across 6 tool groups:\n",
    "- **Company Directory**: Look up employee email addresses\n",
    "- **Email**: Send, search, reply, forward, delete emails\n",
    "- **Calendar**: Create, search, update, delete events\n",
    "- **Analytics**: Query website visitor data and create plots\n",
    "- **Project Management**: Manage tasks across Kanban boards\n",
    "- **CRM**: Manage customer records and sales pipeline\n",
    "\n",
    "These tools are designed to require **multi-step reasoning**. For example:\n",
    "- \"Email John about the meeting\" requires first looking up John's email, then sending\n",
    "- \"Reassign all of Sarah's leads to Mike\" requires looking up emails, searching customers, then updating each one\n",
    "\n",
    "> **Why this matters:** The schemas define valid arguments and values (for example, allowed board/list/status values). We use these constraints to generate realistic user queries and schema-compliant simulated trajectories."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 27 tools across 6 databases\n",
      "\n",
      "Databases:\n",
      "  - company_directory: 1 tools\n",
      "    Employee directory for looking up email addresses by name.\n",
      "  - email: 6 tools\n",
      "    Email inbox and outbox for sending, receiving, and managing emails.\n",
      "  - calendar: 5 tools\n",
      "    Calendar for managing meetings and events.\n",
      "  - analytics: 6 tools\n",
      "    Website analytics data for tracking visitor behavior and engagement.\n",
      "  - project_management: 5 tools\n",
      "    Project management board for tracking tasks across teams.\n",
      "  - customer_relationship_manager: 4 tools\n",
      "    CRM for managing customer records and sales pipeline.\n"
     ]
    }
   ],
   "source": [
    "# Load tool definitions from separate JSON files (one per database)\n",
    "import os\n",
    "\n",
    "TOOLS_DIR = 'tools'\n",
    "\n",
    "# Load environment config\n",
    "with open(os.path.join(TOOLS_DIR, 'environment.json'), 'r') as f:\n",
    "    env_config = json.load(f)\n",
    "\n",
    "SYSTEM_PROMPT = env_config['system_prompt']\n",
    "MULTI_STEP_PATTERNS = env_config['common_multi_step_patterns']\n",
    "\n",
    "# Load tools from each database file\n",
    "DATABASE_FILES = [\n",
    "    'company_directory.json',\n",
    "    'email.json', \n",
    "    'calendar.json',\n",
    "    'analytics.json',\n",
    "    'project_management.json',\n",
    "    'customer_relationship_manager.json'\n",
    "]\n",
    "\n",
    "TOOLS = []\n",
    "DATABASES = {}\n",
    "TOOL_CATEGORIES = {}\n",
    "\n",
    "for db_file in DATABASE_FILES:\n",
    "    with open(os.path.join(TOOLS_DIR, db_file), 'r') as f:\n",
    "        db_config = json.load(f)\n",
    "        \n",
    "    db_name = db_config['database']\n",
    "    DATABASES[db_name] = {\n",
    "        'description': db_config['description'],\n",
    "        'data_schema': db_config['data_schema']\n",
    "    }\n",
    "    \n",
    "    # Add tools and track category\n",
    "    db_tools = db_config['tools']\n",
    "    TOOLS.extend(db_tools)\n",
    "    TOOL_CATEGORIES[db_name] = [t['name'] for t in db_tools]\n",
    "\n",
    "print(f\"Loaded {len(TOOLS)} tools across {len(DATABASES)} databases\")\n",
    "print(f\"\\nDatabases:\")\n",
    "for db_name, db_info in DATABASES.items():\n",
    "    tool_count = len(TOOL_CATEGORIES[db_name])\n",
    "    print(f\"  - {db_name}: {tool_count} tools\")\n",
    "    print(f\"    {db_info['description']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Display all loaded tools grouped by database. This summary shows each tool's name and description."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "### COMPANY_DIRECTORY (1 tools)\n",
      "- **company_directory_find_email_address**: Finds all email addresses containing the given name (case-insensitive search).\n",
      "\n",
      "### EMAIL (6 tools)\n",
      "- **email_get_email_information_by_id**: Retrieves specific details of an email by its ID.\n",
      "- **email_search_emails**: Searches for emails matching the given query across subject, body, or sender fields. The function matches an email if all words in the query appear in any of these fields.\n",
      "- **email_send_email**: Sends an email to the specified recipient.\n",
      "- **email_delete_email**: Deletes an email by its ID.\n",
      "- **email_forward_email**: Forwards an email to the specified recipient.\n",
      "- **email_reply_email**: Replies to an email by its ID.\n",
      "\n",
      "### CALENDAR (5 tools)\n",
      "- **calendar_get_event_information_by_id**: Returns the event for a given ID.\n",
      "- **calendar_search_events**: Returns the events for a given query with pagination support.\n",
      "- **calendar_create_event**: Creates a new event.\n",
      "- **calendar_delete_event**: Deletes an event.\n",
      "- **calendar_update_event**: Updates an event.\n",
      "\n",
      "### ANALYTICS (6 tools)\n",
      "- **analytics_get_visitor_information_by_id**: Returns the analytics data for a given visitor ID.\n",
      "- **analytics_create_plot**: Plots the analytics data for a given time range and value.\n",
      "- **analytics_total_visits_count**: Returns the total number of visits within a specified time range.\n",
      "- **analytics_engaged_users_count**: Returns the number of engaged users within a specified time range.\n",
      "- **analytics_traffic_source_count**: Returns the number of visits from a specific traffic source within a specified time range.\n",
      "- **analytics_get_average_session_duration**: Returns the average session duration within a specified time range.\n",
      "\n",
      "### PROJECT_MANAGEMENT (5 tools)\n",
      "- **project_management_get_task_information_by_id**: Returns the task information for a given ID.\n",
      "- **project_management_search_tasks**: Searches for tasks based on the given parameters.\n",
      "- **project_management_create_task**: Creates a new task.\n",
      "- **project_management_delete_task**: Deletes a task by ID.\n",
      "- **project_management_update_task**: Updates a task by ID.\n",
      "\n",
      "### CUSTOMER_RELATIONSHIP_MANAGER (4 tools)\n",
      "- **customer_relationship_manager_search_customers**: Searches for customers based on the given parameters with pagination support.\n",
      "- **customer_relationship_manager_update_customer**: Updates a customer record by ID.\n",
      "- **customer_relationship_manager_add_customer**: Adds a new customer record.\n",
      "- **customer_relationship_manager_delete_customer**: Deletes a customer record by ID.\n"
     ]
    }
   ],
   "source": [
    "# Helper function to format tools for prompts\n",
    "def format_tools_for_prompt(tools: List[dict], include_schemas: bool = False) -> str:\n",
    "    \"\"\"Format tool definitions into a readable string for LLM prompts.\"\"\"\n",
    "    lines = []\n",
    "    for tool in tools:\n",
    "        lines.append(f\"- **{tool['name']}**: {tool['description']}\")\n",
    "        if include_schemas:\n",
    "            params = tool['parameters']['properties']\n",
    "            if params:\n",
    "                lines.append(f\"  Parameters: {list(params.keys())}\")\n",
    "    return \"\\n\".join(lines)\n",
    "\n",
    "# Display tool summary by category\n",
    "for category, tool_names in TOOL_CATEGORIES.items():\n",
    "    print(f\"\\n### {category.upper()} ({len(tool_names)} tools)\")\n",
    "    category_tools = [t for t in TOOLS if t['name'] in tool_names]\n",
    "    print(format_tools_for_prompt(category_tools))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 3: Define Output Schemas\n",
    "\n",
    "**Data Designer** uses **Pydantic** models to define structured output formats, ensuring the LLM generates data in a consistent, parseable format.\n",
    "\n",
    "We define five schemas:\n",
    "1. **ToolCall** / **AgentStep** / **AgentTrajectory**: Represent a multi-step tool-calling solution\n",
    "2. **UserQueryJudgeScores**: Quality scores for generated user queries\n",
    "3. **TrajectoryJudgeScores**: Quality scores for generated trajectories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ToolCall(BaseModel):\n",
    "    \"\"\"A single tool invocation.\"\"\"\n",
    "    name: str = Field(..., description=\"The name of the tool to call (e.g., 'email_send_email')\")\n",
    "    arguments: str = Field(..., description=\"JSON string of the tool arguments\")\n",
    "\n",
    "\n",
    "class AgentStep(BaseModel):\n",
    "    \"\"\"A single step in the agent's reasoning trajectory.\"\"\"\n",
    "    step_number: int = Field(..., description=\"The step number (1-indexed)\")\n",
    "    thought: str = Field(\n",
    "        ..., \n",
    "        description=\"The agent's reasoning about what to do next and why. Should explain the purpose of the tool call.\"\n",
    "    )\n",
    "    tool_call: ToolCall = Field(..., description=\"The tool to call in this step\")\n",
    "    expected_result: str = Field(\n",
    "        ..., \n",
    "        description=\"What information or state change we expect from this tool call\"\n",
    "    )\n",
    "\n",
    "\n",
    "class AgentTrajectory(BaseModel):\n",
    "    \"\"\"Complete trajectory for solving a multi-step task.\"\"\"\n",
    "    reasoning_trace: List[AgentStep] = Field(\n",
    "        ..., \n",
    "        description=\"The sequence of steps to solve the task. Should be 1-6 steps.\"\n",
    "    )\n",
    "    final_answer: str = Field(\n",
    "        ..., \n",
    "        description=\"A brief confirmation of what was accomplished\"\n",
    "    )\n",
    "\n",
    "\n",
    "class UserQueryJudgeScores(BaseModel):\n",
    "    \"\"\"Quality scores for the generated user query.\"\"\"\n",
    "    feasibility: int = Field(\n",
    "        ..., ge=1, le=5, \n",
    "        description=\"Is the request achievable with the available tools? (1=impossible, 5=fully achievable)\"\n",
    "    )\n",
    "    schema_compliance: int = Field(\n",
    "        ..., ge=1, le=5, \n",
    "        description=\"Does the request use valid values as defined in tool schemas (e.g., valid board names, list names, statuses)? (1=uses invalid values, 5=all values valid)\"\n",
    "    )\n",
    "    naturalness: int = Field(\n",
    "        ..., ge=1, le=5, \n",
    "        description=\"Does the request sound like a natural user query? (1=robotic/artificial, 5=very natural)\"\n",
    "    )\n",
    "    is_valid: bool = Field(\n",
    "        ..., \n",
    "        description=\"True if the query is valid and should be kept, False if it should be discarded\"\n",
    "    )\n",
    "    issues: str = Field(\n",
    "        ..., \n",
    "        description=\"List any issues found (invalid enum values, impossible requests, etc.) or 'None' if valid\"\n",
    "    )\n",
    "\n",
    "\n",
    "class TrajectoryJudgeScores(BaseModel):\n",
    "    \"\"\"Quality scores for the generated trajectory.\"\"\"\n",
    "    tool_validity: int = Field(\n",
    "        ..., ge=1, le=5, \n",
    "        description=\"Are all tool names valid and arguments schema-compliant? (1=invalid tools/args, 5=all valid)\"\n",
    "    )\n",
    "    argument_validity: int = Field(\n",
    "        ..., ge=1, le=5, \n",
    "        description=\"Do all arguments use valid values as specified in tool descriptions? (1=invalid values, 5=all valid)\"\n",
    "    )\n",
    "    completeness: int = Field(\n",
    "        ..., ge=1, le=5, \n",
    "        description=\"Does the trajectory fully solve the user request? (1=incomplete, 5=fully complete)\"\n",
    "    )\n",
    "    efficiency: int = Field(\n",
    "        ..., ge=1, le=5, \n",
    "        description=\"Is the trajectory optimal without unnecessary steps? (1=very inefficient, 5=optimal)\"\n",
    "    )\n",
    "    is_valid: bool = Field(\n",
    "        ..., \n",
    "        description=\"True if the trajectory is valid and executable, False if it has errors\"\n",
    "    )\n",
    "    issues: str = Field(\n",
    "        ..., \n",
    "        description=\"List any issues found (invalid enum values, wrong tool names, missing steps, etc.) or 'None' if valid\"\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 4: Define Generation Prompts\n",
    "\n",
    "The heart of synthetic data generation is the prompts. We define four prompts using **Jinja2 templates** (with `{{ variable }}` placeholders that Data Designer fills from seed columns):\n",
    "\n",
    "1. **User Query Generation**: Create realistic workplace requests\n",
    "2. **Trajectory Simulation**: Generate the step-by-step tool-call solution\n",
    "3. **User Query Judge**: Evaluate query feasibility and schema compliance\n",
    "4. **Trajectory Judge**: Evaluate tool-call correctness and completeness\n",
    "\n",
    "### Key Principles\n",
    "- **Specificity**: Tell the LLM exactly what format you want\n",
    "- **Examples**: Show don't tell ‚Äî include concrete examples by complexity level\n",
    "- **Constraints**: Define what NOT to do (avoid trivial tasks, don't skip steps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "User Query Generation Prompt loaded\n"
     ]
    }
   ],
   "source": [
    "# Prompt 1: Generate a realistic user query that may require one or more tool calls\n",
    "USER_QUERY_GENERATION_PROMPT = \"\"\"\n",
    "You are creating training data for a workplace assistant AI agent.\n",
    "\n",
    "**Your Task:** Generate a realistic user request that requires the agent to use one or more tools to complete.\n",
    "\n",
    "**Available Tools (with full schemas):**\n",
    "{{ tools_json }}\n",
    "\n",
    "**Selected Tool Category:** {{ category }}\n",
    "\n",
    "**Multi-Step Pattern to Use:** {{ pattern }}\n",
    "\n",
    "**CRITICAL - Valid Values:**\n",
    "Many tool parameters have RESTRICTED VALUES specified in their descriptions. You MUST only reference values that exist in the tool schemas. Pay close attention to phrases like \"One of:\" in parameter descriptions.\n",
    "\n",
    "Common restrictions to follow:\n",
    "- `list_name`: Only use 'Backlog', 'In Progress', 'In Review', or 'Completed' (NOT 'Prospects', 'Todo', 'Pipeline', etc.)\n",
    "- `board`: Only use 'Back end', 'Front end', or 'Design' (NOT 'Sales', 'Marketing', 'Engineering', etc.)\n",
    "- `status`: Only use 'Qualified', 'Won', 'Lost', 'Lead', or 'Proposal' (NOT 'Active', 'Prospect', 'Closed', etc.)\n",
    "- `product_interest`: Only use 'Software', 'Hardware', 'Services', 'Consulting', or 'Training'\n",
    "\n",
    "**Guidelines:**\n",
    "1. The request should sound natural - like something a real employee would ask\n",
    "2. It should require 1-6 tool calls to complete\n",
    "3. Include specific details that make the task concrete (names, dates, subjects)\n",
    "4. Don't mention tool names or technical details - speak like a normal user\n",
    "5. The task MUST be achievable with the available tools using ONLY valid parameter values\n",
    "6. When referencing boards, lists, statuses, etc., use EXACTLY the values allowed in the tool schemas\n",
    "\n",
    "**Examples by Complexity:**\n",
    "\n",
    "*Simple (1 step):*\n",
    "- \"Reply to Carlos's last email about the prototype with 'Thanks, I'll review it tomorrow'\"\n",
    "- \"Change the name of my 3pm meeting to 'Risk Management Forum'\"\n",
    "- \"How many website visitors did we have last week?\"\n",
    "\n",
    "*Medium (2-3 steps):*\n",
    "- \"Send an email to John about the quarterly review meeting tomorrow\"\n",
    "- \"Schedule a 30-minute sync with Lisa tomorrow at 2pm\"\n",
    "- \"Get the total visits and engaged users for November\"\n",
    "\n",
    "*Complex (4-6 steps):*\n",
    "- \"Raj is taking over all of Akira's leads that are interested in software. Can you reassign them in the CRM?\"\n",
    "- \"Forward the last email from marketing about the Q4 report to everyone on the design team\"\n",
    "- \"Move all of Sarah's overdue tasks on the Back end board to the Backlog\"\n",
    "\n",
    "**Output:** Return ONLY the user request as a single string. No quotes, no explanation.\n",
    "\"\"\"\n",
    "\n",
    "print(\"User Query Generation Prompt loaded\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trajectory Simulation Prompt loaded\n"
     ]
    }
   ],
   "source": [
    "# Prompt 2: Simulate the agent's trajectory for solving the task\n",
    "TRAJECTORY_SIMULATION_PROMPT = \"\"\"\n",
    "You are simulating an expert workplace assistant agent solving a task step-by-step.\n",
    "\n",
    "**User Request:**\n",
    "{{ user_query }}\n",
    "\n",
    "**System Context:**\n",
    "{{ system_prompt }}\n",
    "\n",
    "**Available Tools:**\n",
    "{{ tools_json }}\n",
    "\n",
    "**Your Task:** Generate a step-by-step trajectory showing how the agent would solve this request.\n",
    "\n",
    "**Guidelines:**\n",
    "1. **Think Step-by-Step**: Each step should have a clear thought explaining WHY we're calling this tool\n",
    "2. **Use Real Tool Names**: The tool_call.name must exactly match one of the available tools\n",
    "3. **Valid JSON Arguments**: The tool_call.arguments must be valid JSON matching the tool's parameter schema\n",
    "4. **Realistic IDs**: When referencing IDs discovered in previous steps, use placeholder format like \"00000001\"\n",
    "5. **Complete the Task**: The trajectory must fully solve the user's request\n",
    "6. **1-6 Steps**: Use the minimum number of steps needed. Simple tasks may need only 1 step.\n",
    "\n",
    "**Common Patterns:**\n",
    "- Look up a person's email before sending them a message\n",
    "- Search for records before updating/deleting them\n",
    "- Get information from one database to use in another\n",
    "- Some tasks can be completed in a single step (e.g., reply to an email, update an event)\n",
    "\n",
    "**Example Step:**\n",
    "{% raw %}\n",
    "```json\n",
    "{\n",
    "  \"step_number\": 1,\n",
    "  \"thought\": \"The user wants to email Raj, but I need his email address first. I'll look it up in the company directory.\",\n",
    "  \"tool_call\": {\n",
    "    \"name\": \"company_directory_find_email_address\",\n",
    "    \"arguments\": \"{\\\"name\\\": \\\"Raj\\\"}\"\n",
    "  },\n",
    "  \"expected_result\": \"Raj's email address (likely raj.patel@atlas.com)\"\n",
    "}\n",
    "```\n",
    "{% endraw %}\n",
    "\n",
    "Output the complete AgentTrajectory with all steps needed to solve the task.\n",
    "\"\"\"\n",
    "\n",
    "print(\"Trajectory Simulation Prompt loaded\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "User Query Judge Prompt loaded\n",
      "Trajectory Judge Prompt loaded\n"
     ]
    }
   ],
   "source": [
    "# Prompt 3a: Judge the quality of the generated USER QUERY\n",
    "USER_QUERY_JUDGE_PROMPT = \"\"\"\n",
    "You are a quality assurance judge evaluating a synthetically generated user query for training an AI workplace assistant.\n",
    "\n",
    "**Generated User Query:**\n",
    "{{ user_query }}\n",
    "\n",
    "**Available Tools (with full schemas):**\n",
    "{{ tools_json }}\n",
    "\n",
    "**Your Task:** Evaluate whether this user query is valid and achievable with the available tools.\n",
    "\n",
    "**CRITICAL - Check for Schema Compliance:**\n",
    "Many tools have RESTRICTED VALUES for certain fields. The user query must only reference values that are valid according to the tool schemas. For example:\n",
    "- If a tool says `list_name` must be one of 'Backlog', 'In Progress', 'In Review', 'Completed' - the query cannot ask for a \"Prospects\" list\n",
    "- If a tool says `board` must be one of 'Back end', 'Front end', 'Design' - the query cannot ask for a \"Sales\" board  \n",
    "- If a tool says `status` must be one of 'Qualified', 'Won', 'Lost', 'Lead', 'Proposal' - the query cannot use other statuses\n",
    "\n",
    "**Evaluation Criteria:**\n",
    "\n",
    "1. **Feasibility (1-5)**: Can this request be fulfilled using the available tools?\n",
    "   - Score 1 if the request requires tools/capabilities that don't exist\n",
    "   - Score 5 if the request is fully achievable with available tools\n",
    "\n",
    "2. **Schema Compliance (1-5)**: Does the request use valid values?\n",
    "   - Score 1 if the query references invalid enum values (wrong board names, list names, statuses, etc.)\n",
    "   - Score 3 if the query is ambiguous but could map to valid values\n",
    "   - Score 5 if all referenced values exactly match valid options in tool schemas\n",
    "\n",
    "3. **Naturalness (1-5)**: Does this sound like a real user request?\n",
    "   - Score 1 if robotic or artificial sounding\n",
    "   - Score 5 if very natural and realistic\n",
    "\n",
    "**is_valid:** Set to False if feasibility < 3 OR schema_compliance < 3. These queries should be discarded.\n",
    "\n",
    "**issues:** List specific problems found. Examples:\n",
    "- \"References 'Sales' board but valid boards are: 'Back end', 'Front end', 'Design'\"\n",
    "- \"References 'Prospects' list but valid lists are: 'Backlog', 'In Progress', 'In Review', 'Completed'\"\n",
    "- \"None\" if no issues found\n",
    "\n",
    "**Output:** Return UserQueryJudgeScores with all fields.\n",
    "\"\"\"\n",
    "\n",
    "# Prompt 3b: Judge the quality of the generated TRAJECTORY\n",
    "TRAJECTORY_JUDGE_PROMPT = \"\"\"\n",
    "You are a quality assurance judge evaluating a generated trajectory (sequence of tool calls) for training an AI workplace assistant.\n",
    "\n",
    "**User Request:**\n",
    "{{ user_query }}\n",
    "\n",
    "**Generated Trajectory:**\n",
    "{{ trajectory }}\n",
    "\n",
    "**Available Tools (with full schemas):**\n",
    "{{ tools_json }}\n",
    "\n",
    "**Your Task:** Evaluate whether this trajectory correctly solves the user request using valid tool calls.\n",
    "\n",
    "**CRITICAL - Check for Argument Validity:**\n",
    "Tool arguments must use EXACTLY the values allowed by the tool schemas. For example:\n",
    "- `list_name` must be one of: 'Backlog', 'In Progress', 'In Review', 'Completed' (NOT 'Prospects', 'Todo', etc.)\n",
    "- `board` must be one of: 'Back end', 'Front end', 'Design' (NOT 'Sales', 'Marketing', etc.)\n",
    "- `status` must be one of: 'Qualified', 'Won', 'Lost', 'Lead', 'Proposal' (NOT 'Active', 'Prospect', etc.)\n",
    "- `product_interest` must be one of: 'Software', 'Hardware', 'Services', 'Consulting', 'Training'\n",
    "\n",
    "**Evaluation Criteria:**\n",
    "\n",
    "1. **Tool Validity (1-5)**: Are all tool names correct?\n",
    "   - Score 1 if any tool name doesn't match available tools\n",
    "   - Score 5 if all tool names exactly match\n",
    "\n",
    "2. **Argument Validity (1-5)**: Are all arguments schema-compliant?\n",
    "   - Score 1 if any argument uses invalid enum values or wrong types\n",
    "   - Score 3 if arguments are mostly valid but some are ambiguous\n",
    "   - Score 5 if all arguments perfectly match the schema requirements\n",
    "\n",
    "3. **Completeness (1-5)**: Does the trajectory fully solve the request?\n",
    "   - Score 1 if major parts of the request are unaddressed\n",
    "   - Score 5 if the trajectory completely fulfills the request\n",
    "\n",
    "4. **Efficiency (1-5)**: Is the trajectory optimal?\n",
    "   - Score 1 if there are many unnecessary steps\n",
    "   - Score 5 if the trajectory is optimal with no wasted steps\n",
    "\n",
    "**is_valid:** Set to False if tool_validity < 4 OR argument_validity < 4. These trajectories have errors and should be discarded.\n",
    "\n",
    "**issues:** List specific problems found. Examples:\n",
    "- \"Step 2 uses list_name='Prospects' but valid values are: 'Backlog', 'In Progress', 'In Review', 'Completed'\"\n",
    "- \"Step 1 calls 'email_send' but correct tool name is 'email_send_email'\"\n",
    "- \"None\" if no issues found\n",
    "\n",
    "**Output:** Return TrajectoryJudgeScores with all fields.\n",
    "\"\"\"\n",
    "\n",
    "print(\"User Query Judge Prompt loaded\")\n",
    "print(\"Trajectory Judge Prompt loaded\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 5: Create Seed Data\n",
    "\n",
    "**Data Designer** works by expanding seed data through LLM generation. Each seed row provides context variables that get substituted into the prompt templates:\n",
    "\n",
    "- `category`: Which tool database to focus on (ensures diversity across domains)\n",
    "- `pattern`: Which multi-step pattern to use (e.g., lookup-then-send, search-then-update)\n",
    "- `tools_json`: Full tool schemas for the LLM to reference\n",
    "- `system_prompt`: The system context for the workplace assistant\n",
    "\n",
    "> **Pattern Engineering Note:** The multi-step patterns used as seeds in `create_seed_data()` are domain-informed. In practice, you can engineer these patterns from heuristics, inferred tool-call chains observed in production traffic, or other rule-based design choices. In this case, we had some common patterns stored in `tools/environments.json`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Created 50 seeds\n",
      "\n",
      "Sample seed:\n",
      "{'seed_id': 0, 'category': 'company_directory', 'pattern': \"lookup_then_send_email: Look up a person's email address, then send them an email\", 'tools_description': \"- **company_directory_find_email_address**: Finds all email addresses containing the given name (case-insensitive search).\\n  Parameters: ['name']\", 'tools_json': '[\\n  {\\n    \"type\": \"function\",\\n    \"name\": \"company_directory_find_email_address\",\\n    \"description\": \"Finds all email addresses containing the given name (case-insensitive search).\",\\n    \"database\": \"company_directory\",\\n    \"operation_type\": \"read\",\\n    \"parameters\": {\\n      \"type\": \"object\",\\n      \"properties\": {\\n        \"name\": {\\n          \"type\": \"string\",\\n          \"description\": \"Name or partial name to search for in email addresses\"\\n        }\\n      },\\n      \"required\": [],\\n      \"additionalProperties\": false\\n    },\\n    \"strict\": false\\n  }\\n]', 'tools_summary': '- **company_directory_find_email_address**: Finds all email addresses containing the given name (case-insensitive search).\\n- **email_get_email_information_by_id**: Retrieves specific details of an email by its ID.\\n- **email_search_emails**: Searches for emails matching the given query across subject, body, or sender fields. The function matches an email if all words in the query appear in any of these fields.\\n- **email_send_email**: Sends an email to the specified recipient.\\n- **email_delete_email**: Deletes an email by its ID.\\n- **email_forward_email**: Forwards an email to the specified recipient.\\n- **email_reply_email**: Replies to an email by its ID.\\n- **calendar_get_event_information_by_id**: Returns the event for a given ID.\\n- **calendar_search_events**: Returns the events for a given query with pagination support.\\n- **calendar_create_event**: Creates a new event.\\n- **calendar_delete_event**: Deletes an event.\\n- **calendar_update_event**: Updates an event.\\n- **analytics_get_visitor_information_by_id**: Returns the analytics data for a given visitor ID.\\n- **analytics_create_plot**: Plots the analytics data for a given time range and value.\\n- **analytics_total_visits_count**: Returns the total number of visits within a specified time range.\\n- **analytics_engaged_users_count**: Returns the number of engaged users within a specified time range.\\n- **analytics_traffic_source_count**: Returns the number of visits from a specific traffic source within a specified time range.\\n- **analytics_get_average_session_duration**: Returns the average session duration within a specified time range.\\n- **project_management_get_task_information_by_id**: Returns the task information for a given ID.\\n- **project_management_search_tasks**: Searches for tasks based on the given parameters.\\n- **project_management_create_task**: Creates a new task.\\n- **project_management_delete_task**: Deletes a task by ID.\\n- **project_management_update_task**: Updates a task by ID.\\n- **customer_relationship_manager_search_customers**: Searches for customers based on the given parameters with pagination support.\\n- **customer_relationship_manager_update_customer**: Updates a customer record by ID.\\n- **customer_relationship_manager_add_customer**: Adds a new customer record.\\n- **customer_relationship_manager_delete_customer**: Deletes a customer record by ID.', 'system_prompt': \"Today's date is Thursday, 2026-01-29 and the current time is 23:59:00. Remember the current date and time when answering queries. Meetings must not start before 9am or end after 6pm.\"}\n"
     ]
    }
   ],
   "source": [
    "def create_seed_data(num_seeds: int = 100) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Create seed data for the Data Designer pipeline.\n",
    "    \n",
    "    Each seed contains:\n",
    "    - category: Which tool category to focus on\n",
    "    - pattern: Which multi-step pattern to use\n",
    "    - tools_description: Formatted tool descriptions\n",
    "    - tools_json: Full tool schemas as JSON\n",
    "    - system_prompt: The system context\n",
    "    \"\"\"\n",
    "    seeds = []\n",
    "    \n",
    "    categories = list(TOOL_CATEGORIES.keys())\n",
    "    patterns = [\n",
    "        f\"{p['pattern']}: {p['description']}\" for p in MULTI_STEP_PATTERNS\n",
    "    ]\n",
    "    \n",
    "    for i in range(num_seeds):\n",
    "        # Select category and pattern (ensuring diversity)\n",
    "        category = categories[i % len(categories)]\n",
    "        pattern = patterns[i % len(patterns)]\n",
    "        \n",
    "        # Get tools for this category (plus company_directory for lookups)\n",
    "        relevant_tool_names = TOOL_CATEGORIES[category] + TOOL_CATEGORIES.get('company_directory', [])\n",
    "        relevant_tools = [t for t in TOOLS if t['name'] in relevant_tool_names]\n",
    "        \n",
    "        seeds.append({\n",
    "            'seed_id': i,\n",
    "            'category': category,\n",
    "            'pattern': pattern,\n",
    "            'tools_description': format_tools_for_prompt(relevant_tools, include_schemas=True),\n",
    "            'tools_json': json.dumps(relevant_tools, indent=2),\n",
    "            'tools_summary': format_tools_for_prompt(TOOLS),  # All tools for judge\n",
    "            'system_prompt': SYSTEM_PROMPT,\n",
    "        })\n",
    "    \n",
    "    return pd.DataFrame(seeds)\n",
    "\n",
    "# Create seed data\n",
    "seed_df = create_seed_data(num_seeds=50)\n",
    "print(f\"Created {len(seed_df)} seeds\")\n",
    "print(f\"\\nSample seed:\")\n",
    "print(seed_df.iloc[0].to_dict())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Save the seed data as a Parquet file for Data Designer to consume."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Seeds saved to workplace_assistant_seeds.parquet\n"
     ]
    }
   ],
   "source": [
    "# Save seeds to parquet for Data Designer\n",
    "seed_df.to_parquet('workplace_assistant_seeds.parquet', index=False)\n",
    "print(\"Seeds saved to workplace_assistant_seeds.parquet\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 6: Configure the Data Designer Pipeline\n",
    "\n",
    "Now we wire everything together into a **Data Designer** workflow:\n",
    "\n",
    "1. **Load Seeds** ‚Äî Provides category, pattern, and tools for each generation\n",
    "2. **Generate User Query** ‚Äî LLM creates a realistic workplace request\n",
    "3. **Judge User Query** ‚Äî LLM validates feasibility and schema compliance\n",
    "4. **Simulate Trajectory** ‚Äî LLM generates the step-by-step tool-call solution\n",
    "5. **Judge Trajectory** ‚Äî LLM validates tool names and argument correctness\n",
    "\n",
    "### Configuration\n",
    "\n",
    "First, set up the **NVIDIA Inference API** provider and model. The API key is read from the `NVIDIA_API_KEY` environment variable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import getpass\n",
    "\n",
    "if \"NVIDIA_API_KEY\" not in os.environ or not os.environ[\"NVIDIA_API_KEY\"]:\n",
    "    os.environ[\"NVIDIA_API_KEY\"] = getpass.getpass(\"Enter your NVIDIA API key: \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define custom provider pointing to NVIDIA Inference API\n",
    "NVIDIA_INFERENCE_URL = \"https://inference-api.nvidia.com/v1\"\n",
    "\n",
    "custom_providers = [\n",
    "    ModelProvider(\n",
    "        name=\"nvidia-inference\",\n",
    "        endpoint=NVIDIA_INFERENCE_URL,\n",
    "        provider_type=\"openai\",\n",
    "        api_key=os.environ.get(\"NVIDIA_API_KEY\", \"\"),\n",
    "    ),\n",
    "]\n",
    "\n",
    "# Model name must match NVIDIA's model identifier\n",
    "MODEL_ID = \"nvidia/openai/gpt-oss-120b\"\n",
    "MODEL_ALIAS = \"gpt-oss-120b\"\n",
    "\n",
    "model_configs = [\n",
    "    ModelConfig(\n",
    "        alias=MODEL_ALIAS,\n",
    "        model=MODEL_ID,\n",
    "        provider=\"nvidia-inference\",\n",
    "        inference_parameters=ChatCompletionInferenceParams(\n",
    "            max_tokens=16384,\n",
    "        ),\n",
    "    )\n",
    "]\n",
    "\n",
    "# Initialize DataDesigner and config builder\n",
    "data_designer = DataDesigner(model_providers=custom_providers)\n",
    "config_builder = DataDesignerConfigBuilder(model_configs=model_configs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Build the pipeline with four generation columns: user query, user query judge, trajectory, and trajectory judge."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pipeline configured with 4 generation columns:\n",
      "  1. user_query (text) - Generate realistic user request\n",
      "  2. user_query_judge (structured) - Validate query feasibility and schema compliance\n",
      "  3. trajectory (structured) - Generate step-by-step solution\n",
      "  4. trajectory_judge (structured) - Validate tool calls and argument values\n"
     ]
    }
   ],
   "source": [
    "def build_workplace_assistant_pipeline():\n",
    "    \"\"\"\n",
    "    Build the complete Data Designer pipeline for generating \n",
    "    multi-step tool-calling training data.\n",
    "    \n",
    "    Pipeline stages:\n",
    "    1. Generate user query\n",
    "    2. Judge user query (filter invalid queries early)\n",
    "    3. Generate trajectory \n",
    "    4. Judge trajectory (filter invalid trajectories)\n",
    "    \"\"\"\n",
    "    \n",
    "    # Initialize the config builder\n",
    "    config_builder = DataDesignerConfigBuilder(model_configs=model_configs)\n",
    "    \n",
    "    # Load seed data\n",
    "    seed_ref = LocalFileSeedSource(path='workplace_assistant_seeds.parquet')\n",
    "    config_builder.with_seed_dataset(seed_ref, sampling_strategy=SamplingStrategy.SHUFFLE)\n",
    "    \n",
    "    # Column 1: Generate User Query\n",
    "    # This creates a realistic workplace request based on the category and pattern\n",
    "    config_builder.add_column(\n",
    "        LLMTextColumnConfig(\n",
    "            name=\"user_query\",\n",
    "            prompt=USER_QUERY_GENERATION_PROMPT,\n",
    "            model_alias=MODEL_ALIAS,\n",
    "        )\n",
    "    )\n",
    "    \n",
    "    # Column 2: Judge User Query\n",
    "    # Validates that the user query is feasible and uses valid enum values\n",
    "    config_builder.add_column(\n",
    "        LLMStructuredColumnConfig(\n",
    "            name=\"user_query_judge\",\n",
    "            prompt=USER_QUERY_JUDGE_PROMPT,\n",
    "            output_format=UserQueryJudgeScores,\n",
    "            model_alias=MODEL_ALIAS,\n",
    "        )\n",
    "    )\n",
    "    \n",
    "    # Column 3: Simulate Agent Trajectory\n",
    "    # This generates the step-by-step solution with tool calls\n",
    "    config_builder.add_column(\n",
    "        LLMStructuredColumnConfig(\n",
    "            name=\"trajectory\",\n",
    "            prompt=TRAJECTORY_SIMULATION_PROMPT,\n",
    "            output_format=AgentTrajectory,\n",
    "            model_alias=MODEL_ALIAS,\n",
    "        )\n",
    "    )\n",
    "    \n",
    "    # Column 4: Judge Trajectory\n",
    "    # Validates that the trajectory uses correct tool names and valid argument values\n",
    "    config_builder.add_column(\n",
    "        LLMStructuredColumnConfig(\n",
    "            name=\"trajectory_judge\",\n",
    "            prompt=TRAJECTORY_JUDGE_PROMPT,\n",
    "            output_format=TrajectoryJudgeScores,\n",
    "            model_alias=MODEL_ALIAS,\n",
    "        )\n",
    "    )\n",
    "    \n",
    "    return config_builder\n",
    "\n",
    "# Build the pipeline\n",
    "pipeline = build_workplace_assistant_pipeline()\n",
    "print(\"Pipeline configured with 4 generation columns:\")\n",
    "print(\"  1. user_query (text) - Generate realistic user request\")\n",
    "print(\"  2. user_query_judge (structured) - Validate query feasibility and schema compliance\")\n",
    "print(\"  3. trajectory (structured) - Generate step-by-step solution\")\n",
    "print(\"  4. trajectory_judge (structured) - Validate tool calls and argument values\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Validate the pipeline configuration to catch any issues before generation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[15:45:07] [INFO] ‚úÖ Validation passed\n"
     ]
    }
   ],
   "source": [
    "data_designer.validate(pipeline)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run a quick preview with 2 records to verify the pipeline produces well-formed outputs before scaling up."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[15:45:09] [INFO] üî≠ Preview generation in progress\n",
      "[15:45:09] [INFO] ‚úÖ Validation passed\n",
      "[15:45:09] [INFO] ‚õìÔ∏è Sorting column configs into a Directed Acyclic Graph\n",
      "[15:45:09] [INFO] ü©∫ Running health checks for models...\n",
      "[15:45:09] [INFO]   |-- üëÄ Checking 'nvidia/openai/gpt-oss-120b' in provider named 'nvidia-inference' for model alias 'gpt-oss-120b'...\n",
      "[15:45:12] [INFO]   |-- ‚úÖ Passed!\n",
      "[15:45:12] [INFO] üå± Sampling 2 records from seed dataset\n",
      "[15:45:12] [INFO]   |-- seed dataset size: 50 records\n",
      "[15:45:12] [INFO]   |-- sampling strategy: shuffle\n",
      "[15:45:12] [INFO] üìù llm-text model config for column 'user_query'\n",
      "[15:45:12] [INFO]   |-- model: 'nvidia/openai/gpt-oss-120b'\n",
      "[15:45:12] [INFO]   |-- model alias: 'gpt-oss-120b'\n",
      "[15:45:12] [INFO]   |-- model provider: 'nvidia-inference'\n",
      "[15:45:12] [INFO]   |-- inference parameters:\n",
      "[15:45:12] [INFO]   |  |-- generation_type=chat-completion\n",
      "[15:45:12] [INFO]   |  |-- max_parallel_requests=4\n",
      "[15:45:12] [INFO]   |  |-- max_tokens=16384\n",
      "[15:45:12] [INFO] ‚ö°Ô∏è Processing llm-text column 'user_query' with 4 concurrent workers\n",
      "[15:45:12] [INFO] ‚è±Ô∏è llm-text column 'user_query' will report progress after each record\n",
      "[15:45:14] [INFO]   |-- üò∏ llm-text column 'user_query' progress: 1/2 (50%) complete, 1 ok, 0 failed, 0.46 rec/s, eta 2.2s\n",
      "[15:45:15] [INFO]   |-- ü¶Å llm-text column 'user_query' progress: 2/2 (100%) complete, 2 ok, 0 failed, 0.85 rec/s, eta 0.0s\n",
      "[15:45:15] [INFO] üóÇÔ∏è llm-structured model config for column 'user_query_judge'\n",
      "[15:45:15] [INFO]   |-- model: 'nvidia/openai/gpt-oss-120b'\n",
      "[15:45:15] [INFO]   |-- model alias: 'gpt-oss-120b'\n",
      "[15:45:15] [INFO]   |-- model provider: 'nvidia-inference'\n",
      "[15:45:15] [INFO]   |-- inference parameters:\n",
      "[15:45:15] [INFO]   |  |-- generation_type=chat-completion\n",
      "[15:45:15] [INFO]   |  |-- max_parallel_requests=4\n",
      "[15:45:15] [INFO]   |  |-- max_tokens=16384\n",
      "[15:45:15] [INFO] ‚ö°Ô∏è Processing llm-structured column 'user_query_judge' with 4 concurrent workers\n",
      "[15:45:15] [INFO] ‚è±Ô∏è llm-structured column 'user_query_judge' will report progress after each record\n",
      "[15:45:17] [INFO]   |-- üò∏ llm-structured column 'user_query_judge' progress: 1/2 (50%) complete, 1 ok, 0 failed, 0.41 rec/s, eta 2.4s\n",
      "[15:45:18] [INFO]   |-- ü¶Å llm-structured column 'user_query_judge' progress: 2/2 (100%) complete, 2 ok, 0 failed, 0.62 rec/s, eta 0.0s\n",
      "[15:45:18] [INFO] üóÇÔ∏è llm-structured model config for column 'trajectory'\n",
      "[15:45:18] [INFO]   |-- model: 'nvidia/openai/gpt-oss-120b'\n",
      "[15:45:18] [INFO]   |-- model alias: 'gpt-oss-120b'\n",
      "[15:45:18] [INFO]   |-- model provider: 'nvidia-inference'\n",
      "[15:45:18] [INFO]   |-- inference parameters:\n",
      "[15:45:18] [INFO]   |  |-- generation_type=chat-completion\n",
      "[15:45:18] [INFO]   |  |-- max_parallel_requests=4\n",
      "[15:45:18] [INFO]   |  |-- max_tokens=16384\n",
      "[15:45:18] [INFO] ‚ö°Ô∏è Processing llm-structured column 'trajectory' with 4 concurrent workers\n",
      "[15:45:18] [INFO] ‚è±Ô∏è llm-structured column 'trajectory' will report progress after each record\n",
      "[15:45:23] [INFO]   |-- üöó llm-structured column 'trajectory' progress: 1/2 (50%) complete, 1 ok, 0 failed, 0.21 rec/s, eta 4.8s\n",
      "[15:45:24] [INFO]   |-- üöÄ llm-structured column 'trajectory' progress: 2/2 (100%) complete, 2 ok, 0 failed, 0.35 rec/s, eta 0.0s\n",
      "[15:45:24] [INFO] üóÇÔ∏è llm-structured model config for column 'trajectory_judge'\n",
      "[15:45:24] [INFO]   |-- model: 'nvidia/openai/gpt-oss-120b'\n",
      "[15:45:24] [INFO]   |-- model alias: 'gpt-oss-120b'\n",
      "[15:45:24] [INFO]   |-- model provider: 'nvidia-inference'\n",
      "[15:45:24] [INFO]   |-- inference parameters:\n",
      "[15:45:24] [INFO]   |  |-- generation_type=chat-completion\n",
      "[15:45:24] [INFO]   |  |-- max_parallel_requests=4\n",
      "[15:45:24] [INFO]   |  |-- max_tokens=16384\n",
      "[15:45:24] [INFO] ‚ö°Ô∏è Processing llm-structured column 'trajectory_judge' with 4 concurrent workers\n",
      "[15:45:24] [INFO] ‚è±Ô∏è llm-structured column 'trajectory_judge' will report progress after each record\n",
      "[15:45:26] [INFO]   |-- üê• llm-structured column 'trajectory_judge' progress: 1/2 (50%) complete, 1 ok, 0 failed, 0.49 rec/s, eta 2.1s\n",
      "[15:45:26] [INFO]   |-- üêî llm-structured column 'trajectory_judge' progress: 2/2 (100%) complete, 2 ok, 0 failed, 0.72 rec/s, eta 0.0s\n",
      "[15:45:27] [INFO] üìä Model usage summary:\n",
      "[15:45:27] [INFO]   |-- model: nvidia/openai/gpt-oss-120b\n",
      "[15:45:27] [INFO]   |-- tokens: input=15944, output=4466, total=20410, tps=1417\n",
      "[15:45:27] [INFO]   |-- requests: success=8, failed=0, total=8, rpm=33\n",
      "[15:45:27] [INFO] üìê Measuring dataset column statistics:\n",
      "[15:45:27] [INFO]   |-- üìù column: 'user_query'\n",
      "[15:45:27] [INFO]   |-- üóÇÔ∏è column: 'user_query_judge'\n",
      "[15:45:27] [INFO]   |-- üóÇÔ∏è column: 'trajectory'\n",
      "[15:45:27] [INFO]   |-- üóÇÔ∏è column: 'trajectory_judge'\n",
      "[15:45:27] [INFO] üèÜ Preview complete!\n"
     ]
    }
   ],
   "source": [
    "preview = data_designer.preview(pipeline, num_records=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Inspect a sample generated user query from the preview."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>seed_id</th>\n",
       "      <th>category</th>\n",
       "      <th>pattern</th>\n",
       "      <th>tools_description</th>\n",
       "      <th>tools_json</th>\n",
       "      <th>tools_summary</th>\n",
       "      <th>system_prompt</th>\n",
       "      <th>user_query</th>\n",
       "      <th>user_query_judge</th>\n",
       "      <th>trajectory</th>\n",
       "      <th>trajectory_judge</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>17</td>\n",
       "      <td>customer_relationship_manager</td>\n",
       "      <td>get_task_info_then_update: Get specific task i...</td>\n",
       "      <td>- **company_directory_find_email_address**: Fi...</td>\n",
       "      <td>[\\n  {\\n    \"type\": \"function\",\\n    \"name\": \"...</td>\n",
       "      <td>- **company_directory_find_email_address**: Fi...</td>\n",
       "      <td>Today's date is Thursday, 2026-01-29 and the c...</td>\n",
       "      <td>Can you find the customer John Doe who is a Le...</td>\n",
       "      <td>{'feasibility': 5, 'schema_compliance': 5, 'na...</td>\n",
       "      <td>{'reasoning_trace': [{'step_number': 1, 'thoug...</td>\n",
       "      <td>{'tool_validity': 5, 'argument_validity': 5, '...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>7</td>\n",
       "      <td>email</td>\n",
       "      <td>search_then_batch_delete_events: Search for ca...</td>\n",
       "      <td>- **company_directory_find_email_address**: Fi...</td>\n",
       "      <td>[\\n  {\\n    \"type\": \"function\",\\n    \"name\": \"...</td>\n",
       "      <td>- **company_directory_find_email_address**: Fi...</td>\n",
       "      <td>Today's date is Thursday, 2026-01-29 and the c...</td>\n",
       "      <td>I need to clean up my inbox‚Äîplease find all em...</td>\n",
       "      <td>{'feasibility': 5, 'schema_compliance': 5, 'na...</td>\n",
       "      <td>{'reasoning_trace': [{'step_number': 1, 'thoug...</td>\n",
       "      <td>{'tool_validity': 5, 'argument_validity': 5, '...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   seed_id                       category  \\\n",
       "0       17  customer_relationship_manager   \n",
       "1        7                          email   \n",
       "\n",
       "                                             pattern  \\\n",
       "0  get_task_info_then_update: Get specific task i...   \n",
       "1  search_then_batch_delete_events: Search for ca...   \n",
       "\n",
       "                                   tools_description  \\\n",
       "0  - **company_directory_find_email_address**: Fi...   \n",
       "1  - **company_directory_find_email_address**: Fi...   \n",
       "\n",
       "                                          tools_json  \\\n",
       "0  [\\n  {\\n    \"type\": \"function\",\\n    \"name\": \"...   \n",
       "1  [\\n  {\\n    \"type\": \"function\",\\n    \"name\": \"...   \n",
       "\n",
       "                                       tools_summary  \\\n",
       "0  - **company_directory_find_email_address**: Fi...   \n",
       "1  - **company_directory_find_email_address**: Fi...   \n",
       "\n",
       "                                       system_prompt  \\\n",
       "0  Today's date is Thursday, 2026-01-29 and the c...   \n",
       "1  Today's date is Thursday, 2026-01-29 and the c...   \n",
       "\n",
       "                                          user_query  \\\n",
       "0  Can you find the customer John Doe who is a Le...   \n",
       "1  I need to clean up my inbox‚Äîplease find all em...   \n",
       "\n",
       "                                    user_query_judge  \\\n",
       "0  {'feasibility': 5, 'schema_compliance': 5, 'na...   \n",
       "1  {'feasibility': 5, 'schema_compliance': 5, 'na...   \n",
       "\n",
       "                                          trajectory  \\\n",
       "0  {'reasoning_trace': [{'step_number': 1, 'thoug...   \n",
       "1  {'reasoning_trace': [{'step_number': 1, 'thoug...   \n",
       "\n",
       "                                    trajectory_judge  \n",
       "0  {'tool_validity': 5, 'argument_validity': 5, '...  \n",
       "1  {'tool_validity': 5, 'argument_validity': 5, '...  "
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preview.dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('Can you find the customer John Doe who is a Lead interested in Software and reassign it to sarah.lee@company.com, then set the follow‚Äëup date to 2024-04-30?',\n",
       " {'reasoning_trace': [{'step_number': 1,\n",
       "    'thought': 'I need to locate the specific customer record for John Doe who is a Lead interested in Software. I will search the CRM using those criteria.',\n",
       "    'tool_call': {'name': 'customer_relationship_manager_search_customers',\n",
       "     'arguments': '{\"customer_name\": \"John Doe\", \"status\": \"Lead\", \"product_interest\": \"Software\", \"page\": 1, \"page_size\": 10}'},\n",
       "    'expected_result': 'A list of matching customers, including the customer\\'s ID (e.g., \"00000001\").'},\n",
       "   {'step_number': 2,\n",
       "    'thought': \"Now that I have the customer's ID, I will reassign the customer to sarah.lee@company.com by updating the 'assigned_to_email' field.\",\n",
       "    'tool_call': {'name': 'customer_relationship_manager_update_customer',\n",
       "     'arguments': '{\"customer_id\": \"00000001\", \"field\": \"assigned_to_email\", \"new_value\": \"sarah.lee@company.com\"}'},\n",
       "    'expected_result': \"Confirmation that the 'assigned_to_email' field was updated for customer ID 00000001.\"},\n",
       "   {'step_number': 3,\n",
       "    'thought': \"Finally, I will set the follow‚Äëup date to 2024‚Äë04‚Äë30 by updating the 'follow_up_by' field for the same customer.\",\n",
       "    'tool_call': {'name': 'customer_relationship_manager_update_customer',\n",
       "     'arguments': '{\"customer_id\": \"00000001\", \"field\": \"follow_up_by\", \"new_value\": \"2024-04-30\"}'},\n",
       "    'expected_result': \"Confirmation that the 'follow_up_by' field was updated for customer ID 00000001.\"}],\n",
       "  'final_answer': 'John Doe has been reassigned to sarah.lee@company.com and the follow‚Äëup date has been set to 2024‚Äë04‚Äë30.'})"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preview.dataset.user_query[0], preview.dataset.trajectory[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 7: Set Up Quality Filtering (Generic)\n",
    "\n",
    "Before any downstream format conversion, we apply dual-level quality filtering to keep only high-quality examples.\n",
    "\n",
    "This stage is generic to **Data Designer** workflows and not specific to NeMo Gym.\n",
    "\n",
    "To keep this notebook clean, quality filtering helpers live in `utils/quality_filtering.py`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils import filter_high_quality, show_rejection_reasons"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 8: Generate and Filter the Dataset\n",
    "\n",
    "Run the full pipeline end-to-end: generate records and apply **dual-level quality filtering**.\n",
    "\n",
    "```\n",
    "‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê    ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê    ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê    ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê\n",
    "‚îÇ   Generate   ‚îÇ‚îÄ‚îÄ‚îÄ‚ñ∂‚îÇ Stage 1:     ‚îÇ‚îÄ‚îÄ‚îÄ‚ñ∂‚îÇ Stage 2:     ‚îÇ‚îÄ‚îÄ‚îÄ‚ñ∂‚îÇ   Filtered   ‚îÇ\n",
    "‚îÇ   Records    ‚îÇ    ‚îÇ Query Judge  ‚îÇ    ‚îÇ Traj Judge   ‚îÇ    ‚îÇ   Dataset    ‚îÇ\n",
    "‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò    ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò    ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò    ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò\n",
    "```\n",
    "\n",
    "**Utility location:** `utils/quality_filtering.py`\n",
    "\n",
    "**Quick usage:**\n",
    "- Run `show_rejection_reasons(results_df, num_examples=3)` to inspect failures\n",
    "- Run `filter_high_quality(results_df, verbose=True)` to apply default strict filtering\n",
    "- Optionally tune thresholds with `FilterThresholds(...).to_kwargs()`\n",
    "\n",
    "**Why Dual-Level Filtering?**\n",
    "- **Stage 1 (User Query)**: Catches queries like which are intractable in this context.\n",
    "- **Stage 2 (Trajectory)**: Catches tool argument errors that slipped through, or that doesn't answer the query."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[15:45:43] [INFO] üé® Creating Data Designer dataset\n",
      "[15:45:43] [INFO] ‚úÖ Validation passed\n",
      "[15:45:43] [INFO] ‚õìÔ∏è Sorting column configs into a Directed Acyclic Graph\n",
      "[15:45:44] [INFO] ü©∫ Running health checks for models...\n",
      "[15:45:44] [INFO]   |-- üëÄ Checking 'nvidia/openai/gpt-oss-120b' in provider named 'nvidia-inference' for model alias 'gpt-oss-120b'...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating 10 examples...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[15:45:44] [INFO]   |-- ‚úÖ Passed!\n",
      "[15:45:44] [INFO] üìÇ Dataset path '/Users/shashankv/Documents/Work/workplace-asst-sdg/DataDesigner/docs/colab_notebooks/5-multistep-toolcalling/artifacts/dataset' already exists. Dataset from this session\n",
      "\t\t     will be saved to '/Users/shashankv/Documents/Work/workplace-asst-sdg/DataDesigner/docs/colab_notebooks/5-multistep-toolcalling/artifacts/dataset_02-12-2026_154544' instead.\n",
      "[15:45:44] [INFO] ‚è≥ Processing batch 1 of 1\n",
      "[15:45:44] [INFO] üå± Sampling 10 records from seed dataset\n",
      "[15:45:44] [INFO]   |-- seed dataset size: 50 records\n",
      "[15:45:44] [INFO]   |-- sampling strategy: shuffle\n",
      "[15:45:44] [INFO] üìù llm-text model config for column 'user_query'\n",
      "[15:45:44] [INFO]   |-- model: 'nvidia/openai/gpt-oss-120b'\n",
      "[15:45:44] [INFO]   |-- model alias: 'gpt-oss-120b'\n",
      "[15:45:44] [INFO]   |-- model provider: 'nvidia-inference'\n",
      "[15:45:44] [INFO]   |-- inference parameters:\n",
      "[15:45:44] [INFO]   |  |-- generation_type=chat-completion\n",
      "[15:45:44] [INFO]   |  |-- max_parallel_requests=4\n",
      "[15:45:44] [INFO]   |  |-- max_tokens=16384\n",
      "[15:45:44] [INFO] ‚ö°Ô∏è Processing llm-text column 'user_query' with 4 concurrent workers\n",
      "[15:45:44] [INFO] ‚è±Ô∏è llm-text column 'user_query' will report progress after each record\n",
      "[15:45:46] [INFO]   |-- üåßÔ∏è llm-text column 'user_query' progress: 1/10 (10%) complete, 1 ok, 0 failed, 0.52 rec/s, eta 17.4s\n",
      "[15:45:46] [INFO]   |-- üåßÔ∏è llm-text column 'user_query' progress: 2/10 (20%) complete, 2 ok, 0 failed, 1.02 rec/s, eta 7.9s\n",
      "[15:45:46] [INFO]   |-- üå¶Ô∏è llm-text column 'user_query' progress: 3/10 (30%) complete, 3 ok, 0 failed, 1.46 rec/s, eta 4.8s\n",
      "[15:45:47] [INFO]   |-- üå¶Ô∏è llm-text column 'user_query' progress: 4/10 (40%) complete, 4 ok, 0 failed, 1.34 rec/s, eta 4.5s\n",
      "[15:45:47] [INFO]   |-- ‚õÖ llm-text column 'user_query' progress: 5/10 (50%) complete, 5 ok, 0 failed, 1.45 rec/s, eta 3.5s\n",
      "[15:45:48] [INFO]   |-- ‚õÖ llm-text column 'user_query' progress: 6/10 (60%) complete, 6 ok, 0 failed, 1.38 rec/s, eta 2.9s\n",
      "[15:45:48] [INFO]   |-- ‚õÖ llm-text column 'user_query' progress: 7/10 (70%) complete, 7 ok, 0 failed, 1.53 rec/s, eta 2.0s\n",
      "[15:45:49] [INFO]   |-- üå§Ô∏è llm-text column 'user_query' progress: 8/10 (80%) complete, 8 ok, 0 failed, 1.56 rec/s, eta 1.3s\n",
      "[15:45:49] [INFO]   |-- üå§Ô∏è llm-text column 'user_query' progress: 9/10 (90%) complete, 9 ok, 0 failed, 1.73 rec/s, eta 0.6s\n",
      "[15:45:51] [INFO]   |-- ‚òÄÔ∏è llm-text column 'user_query' progress: 10/10 (100%) complete, 10 ok, 0 failed, 1.45 rec/s, eta 0.0s\n",
      "[15:45:51] [INFO] üóÇÔ∏è llm-structured model config for column 'user_query_judge'\n",
      "[15:45:51] [INFO]   |-- model: 'nvidia/openai/gpt-oss-120b'\n",
      "[15:45:51] [INFO]   |-- model alias: 'gpt-oss-120b'\n",
      "[15:45:51] [INFO]   |-- model provider: 'nvidia-inference'\n",
      "[15:45:51] [INFO]   |-- inference parameters:\n",
      "[15:45:51] [INFO]   |  |-- generation_type=chat-completion\n",
      "[15:45:51] [INFO]   |  |-- max_parallel_requests=4\n",
      "[15:45:51] [INFO]   |  |-- max_tokens=16384\n",
      "[15:45:51] [INFO] ‚ö°Ô∏è Processing llm-structured column 'user_query_judge' with 4 concurrent workers\n",
      "[15:45:51] [INFO] ‚è±Ô∏è llm-structured column 'user_query_judge' will report progress after each record\n",
      "[15:45:52] [INFO]   |-- üåßÔ∏è llm-structured column 'user_query_judge' progress: 1/10 (10%) complete, 1 ok, 0 failed, 0.61 rec/s, eta 14.7s\n",
      "[15:45:52] [INFO]   |-- üåßÔ∏è llm-structured column 'user_query_judge' progress: 2/10 (20%) complete, 2 ok, 0 failed, 1.13 rec/s, eta 7.1s\n",
      "[15:45:53] [INFO]   |-- üå¶Ô∏è llm-structured column 'user_query_judge' progress: 3/10 (30%) complete, 3 ok, 0 failed, 1.56 rec/s, eta 4.5s\n",
      "[15:45:54] [INFO]   |-- üå¶Ô∏è llm-structured column 'user_query_judge' progress: 4/10 (40%) complete, 4 ok, 0 failed, 1.33 rec/s, eta 4.5s\n",
      "[15:45:54] [INFO]   |-- ‚õÖ llm-structured column 'user_query_judge' progress: 5/10 (50%) complete, 5 ok, 0 failed, 1.49 rec/s, eta 3.4s\n",
      "[15:45:54] [INFO]   |-- ‚õÖ llm-structured column 'user_query_judge' progress: 6/10 (60%) complete, 6 ok, 0 failed, 1.61 rec/s, eta 2.5s\n",
      "[15:45:55] [INFO]   |-- ‚õÖ llm-structured column 'user_query_judge' progress: 7/10 (70%) complete, 7 ok, 0 failed, 1.70 rec/s, eta 1.8s\n",
      "[15:45:56] [INFO]   |-- üå§Ô∏è llm-structured column 'user_query_judge' progress: 8/10 (80%) complete, 8 ok, 0 failed, 1.65 rec/s, eta 1.2s\n",
      "[15:45:56] [INFO]   |-- üå§Ô∏è llm-structured column 'user_query_judge' progress: 9/10 (90%) complete, 9 ok, 0 failed, 1.58 rec/s, eta 0.6s\n",
      "[15:46:02] [INFO]   |-- ‚òÄÔ∏è llm-structured column 'user_query_judge' progress: 10/10 (100%) complete, 10 ok, 0 failed, 0.90 rec/s, eta 0.0s\n",
      "[15:46:02] [INFO] üóÇÔ∏è llm-structured model config for column 'trajectory'\n",
      "[15:46:02] [INFO]   |-- model: 'nvidia/openai/gpt-oss-120b'\n",
      "[15:46:02] [INFO]   |-- model alias: 'gpt-oss-120b'\n",
      "[15:46:02] [INFO]   |-- model provider: 'nvidia-inference'\n",
      "[15:46:02] [INFO]   |-- inference parameters:\n",
      "[15:46:02] [INFO]   |  |-- generation_type=chat-completion\n",
      "[15:46:02] [INFO]   |  |-- max_parallel_requests=4\n",
      "[15:46:02] [INFO]   |  |-- max_tokens=16384\n",
      "[15:46:02] [INFO] ‚ö°Ô∏è Processing llm-structured column 'trajectory' with 4 concurrent workers\n",
      "[15:46:02] [INFO] ‚è±Ô∏è llm-structured column 'trajectory' will report progress after each record\n",
      "[15:46:09] [INFO]   |-- üê± llm-structured column 'trajectory' progress: 1/10 (10%) complete, 1 ok, 0 failed, 0.14 rec/s, eta 62.4s\n",
      "[15:46:11] [INFO]   |-- üê± llm-structured column 'trajectory' progress: 2/10 (20%) complete, 2 ok, 0 failed, 0.22 rec/s, eta 35.8s\n",
      "[15:46:13] [INFO]   |-- üò∫ llm-structured column 'trajectory' progress: 3/10 (30%) complete, 3 ok, 0 failed, 0.28 rec/s, eta 25.2s\n",
      "[15:46:14] [INFO]   |-- üò∫ llm-structured column 'trajectory' progress: 4/10 (40%) complete, 4 ok, 0 failed, 0.34 rec/s, eta 17.8s\n",
      "[15:46:15] [INFO]   |-- üò∏ llm-structured column 'trajectory' progress: 5/10 (50%) complete, 5 ok, 0 failed, 0.39 rec/s, eta 13.0s\n",
      "[15:46:17] [INFO]   |-- üò∏ llm-structured column 'trajectory' progress: 6/10 (60%) complete, 6 ok, 0 failed, 0.40 rec/s, eta 9.9s\n",
      "[15:46:18] [INFO]   |-- üò∏ llm-structured column 'trajectory' progress: 7/10 (70%) complete, 7 ok, 0 failed, 0.43 rec/s, eta 7.0s\n",
      "[15:46:20] [INFO]   |-- üòº llm-structured column 'trajectory' progress: 8/10 (80%) complete, 8 ok, 0 failed, 0.44 rec/s, eta 4.5s\n",
      "[15:46:22] [INFO]   |-- üòº llm-structured column 'trajectory' progress: 9/10 (90%) complete, 9 ok, 0 failed, 0.44 rec/s, eta 2.3s\n",
      "[15:46:24] [INFO]   |-- ü¶Å llm-structured column 'trajectory' progress: 10/10 (100%) complete, 10 ok, 0 failed, 0.46 rec/s, eta 0.0s\n",
      "[15:46:24] [INFO] üóÇÔ∏è llm-structured model config for column 'trajectory_judge'\n",
      "[15:46:24] [INFO]   |-- model: 'nvidia/openai/gpt-oss-120b'\n",
      "[15:46:24] [INFO]   |-- model alias: 'gpt-oss-120b'\n",
      "[15:46:24] [INFO]   |-- model provider: 'nvidia-inference'\n",
      "[15:46:24] [INFO]   |-- inference parameters:\n",
      "[15:46:24] [INFO]   |  |-- generation_type=chat-completion\n",
      "[15:46:24] [INFO]   |  |-- max_parallel_requests=4\n",
      "[15:46:24] [INFO]   |  |-- max_tokens=16384\n",
      "[15:46:24] [INFO] ‚ö°Ô∏è Processing llm-structured column 'trajectory_judge' with 4 concurrent workers\n",
      "[15:46:24] [INFO] ‚è±Ô∏è llm-structured column 'trajectory_judge' will report progress after each record\n",
      "[15:46:26] [INFO]   |-- üö∂ llm-structured column 'trajectory_judge' progress: 1/10 (10%) complete, 1 ok, 0 failed, 0.40 rec/s, eta 22.7s\n",
      "[15:46:27] [INFO]   |-- üö∂ llm-structured column 'trajectory_judge' progress: 2/10 (20%) complete, 2 ok, 0 failed, 0.63 rec/s, eta 12.8s\n",
      "[15:46:27] [INFO]   |-- üê¥ llm-structured column 'trajectory_judge' progress: 3/10 (30%) complete, 3 ok, 0 failed, 0.84 rec/s, eta 8.3s\n",
      "[15:46:28] [INFO]   |-- üê¥ llm-structured column 'trajectory_judge' progress: 4/10 (40%) complete, 4 ok, 0 failed, 0.86 rec/s, eta 7.0s\n",
      "[15:46:29] [INFO]   |-- üöó llm-structured column 'trajectory_judge' progress: 5/10 (50%) complete, 5 ok, 0 failed, 0.93 rec/s, eta 5.4s\n",
      "[15:46:30] [INFO]   |-- üöó llm-structured column 'trajectory_judge' progress: 6/10 (60%) complete, 6 ok, 0 failed, 0.99 rec/s, eta 4.0s\n",
      "[15:46:30] [INFO]   |-- üöó llm-structured column 'trajectory_judge' progress: 7/10 (70%) complete, 7 ok, 0 failed, 1.16 rec/s, eta 2.6s\n",
      "[15:46:32] [INFO]   |-- ‚úàÔ∏è llm-structured column 'trajectory_judge' progress: 8/10 (80%) complete, 8 ok, 0 failed, 1.00 rec/s, eta 2.0s\n",
      "[15:46:33] [INFO]   |-- ‚úàÔ∏è llm-structured column 'trajectory_judge' progress: 9/10 (90%) complete, 9 ok, 0 failed, 0.99 rec/s, eta 1.0s\n",
      "[15:46:34] [INFO]   |-- üöÄ llm-structured column 'trajectory_judge' progress: 10/10 (100%) complete, 10 ok, 0 failed, 1.00 rec/s, eta 0.0s\n",
      "[15:46:34] [INFO] üìä Model usage summary:\n",
      "[15:46:34] [INFO]   |-- model: nvidia/openai/gpt-oss-120b\n",
      "[15:46:34] [INFO]   |-- tokens: input=71735, output=23947, total=95682, tps=1908\n",
      "[15:46:34] [INFO]   |-- requests: success=40, failed=0, total=40, rpm=47\n",
      "[15:46:34] [INFO] üìê Measuring dataset column statistics:\n",
      "[15:46:34] [INFO]   |-- üìù column: 'user_query'\n",
      "[15:46:34] [INFO]   |-- üóÇÔ∏è column: 'user_query_judge'\n",
      "[15:46:34] [INFO]   |-- üóÇÔ∏è column: 'trajectory'\n",
      "[15:46:34] [INFO]   |-- üóÇÔ∏è column: 'trajectory_judge'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Generated 10 records\n",
      "\n",
      "Columns: ['seed_id', 'category', 'pattern', 'tools_description', 'tools_json', 'tools_summary', 'system_prompt', 'user_query', 'user_query_judge', 'trajectory', 'trajectory_judge']\n"
     ]
    }
   ],
   "source": [
    "print(\"Generating 10 examples...\")\n",
    "results = data_designer.create(pipeline, num_records=10)\n",
    "\n",
    "results_df = results.load_dataset()\n",
    "print(f\"\\nGenerated {len(results_df)} records\")\n",
    "print(\"\\nColumns:\", list(results_df.columns))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Inspect rejection reasons at both judge levels to understand what kinds of errors the pipeline catches."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== User Query Issues (2/10 rejected) ===\n",
      "  [1] I‚Äôd like a list of all the calendar events I have in the next two weeks that involve John Doe or jan...\n",
      "      Issues: calendar_create_event only accepts a single participant_email, so a meeting involving both John Doe and jane.smith@example.com cannot be created as a single event with the available tools.\n",
      "  [2] Please find every email I received from Sarah Johnson from March 1‚Äë15, 2024 that mentions the Q1 bud...\n",
      "      Issues: email_forward_email does not support adding a custom note to the forwarded message, so the request to forward each email with the added note cannot be fully satisfied.\n",
      "\n",
      "=== Trajectory Issues (1/10 rejected) ===\n",
      "  [1] I‚Äôd like a list of all the calendar events I have in the next two weeks that involve John Doe or jan...\n",
      "      Issues: Step 2 uses a past time range (2026-01-29 to 2026-02-12) instead of the next two weeks from today. Step 3 provides participant_email as a comma‚Äëseparated list, but the schema expects a single email string. Step 3 schedules the meeting on 2026-02-06, which is not the requested next Thursday at 3‚ÄØPM.\n"
     ]
    }
   ],
   "source": [
    "show_rejection_reasons(results_df, num_examples=3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Apply dual-level filtering with strict schema compliance requirements. Records must pass **both** the user query judge and the trajectory judge to be kept."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Quality Filtering Results ===\n",
      "Total records: 10\n",
      "\n",
      "Stage 1 (User Query):  8/10 passed (80%)\n",
      "  is_valid: 8 | feasibility>=3: 8 | schema>=4: 10 | naturalness>=3: 10\n",
      "\n",
      "Stage 2 (Trajectory): 6/10 passed (60%)\n",
      "  is_valid: 9 | tool_validity>=4: 10 | arg_validity>=4: 9 | completeness>=3: 6 | efficiency>=3: 10\n",
      "\n",
      "Final: 6/10 passed (60%)\n"
     ]
    }
   ],
   "source": [
    "filtered_df = filter_high_quality(\n",
    "    results_df,\n",
    "    min_query_feasibility=3,\n",
    "    min_query_schema_compliance=4,\n",
    "    min_query_naturalness=3,\n",
    "    min_trajectory_tool_validity=4,\n",
    "    min_trajectory_argument_validity=4,\n",
    "    min_trajectory_completeness=3,\n",
    "    min_trajectory_efficiency=3,\n",
    "    verbose=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 9 (Optional): Convert to NeMo Gym Format and Save\n",
    "\n",
    "If you plan to use this data with **NeMo Gym**, convert filtered records into NeMo Gym JSONL format and save them.\n",
    "\n",
    "This conversion is NeMo Gym-specific and optional for generic Data Designer workflows."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved 6 examples to workplace_assistant_train-gpt-oss.jsonl\n",
      "\n",
      "Sample generated data (passed both quality stages):\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>seed_id</th>\n",
       "      <th>category</th>\n",
       "      <th>pattern</th>\n",
       "      <th>tools_description</th>\n",
       "      <th>tools_json</th>\n",
       "      <th>tools_summary</th>\n",
       "      <th>system_prompt</th>\n",
       "      <th>user_query</th>\n",
       "      <th>user_query_judge</th>\n",
       "      <th>trajectory</th>\n",
       "      <th>trajectory_judge</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>35</td>\n",
       "      <td>customer_relationship_manager</td>\n",
       "      <td>search_then_batch_delete_events: Search for ca...</td>\n",
       "      <td>- **company_directory_find_email_address**: Fi...</td>\n",
       "      <td>[\n",
       "  {\n",
       "    \"type\": \"function\",\n",
       "    \"name\": \"com...</td>\n",
       "      <td>- **company_directory_find_email_address**: Fi...</td>\n",
       "      <td>Today's date is Thursday, 2026-01-29 and the c...</td>\n",
       "      <td>Please delete all customers assigned to me (al...</td>\n",
       "      <td>{'feasibility': 5, 'is_valid': True, 'issues':...</td>\n",
       "      <td>{'final_answer': 'All customers assigned to al...</td>\n",
       "      <td>{'argument_validity': 5, 'completeness': 3, 'e...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>45</td>\n",
       "      <td>analytics</td>\n",
       "      <td>get_task_info_then_update: Get specific task i...</td>\n",
       "      <td>- **company_directory_find_email_address**: Fi...</td>\n",
       "      <td>[\n",
       "  {\n",
       "    \"type\": \"function\",\n",
       "    \"name\": \"com...</td>\n",
       "      <td>- **company_directory_find_email_address**: Fi...</td>\n",
       "      <td>Today's date is Thursday, 2026-01-29 and the c...</td>\n",
       "      <td>Can you tell me how many website visits we had...</td>\n",
       "      <td>{'feasibility': 5, 'is_valid': True, 'issues':...</td>\n",
       "      <td>{'final_answer': 'I have retrieved the total n...</td>\n",
       "      <td>{'argument_validity': 5, 'completeness': 3, 'e...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>46</td>\n",
       "      <td>project_management</td>\n",
       "      <td>lookup_then_add_customer: Look up a sales rep'...</td>\n",
       "      <td>- **company_directory_find_email_address**: Fi...</td>\n",
       "      <td>[\n",
       "  {\n",
       "    \"type\": \"function\",\n",
       "    \"name\": \"com...</td>\n",
       "      <td>- **company_directory_find_email_address**: Fi...</td>\n",
       "      <td>Today's date is Thursday, 2026-01-29 and the c...</td>\n",
       "      <td>I need to add a follow‚Äëup task for our new cli...</td>\n",
       "      <td>{'feasibility': 5, 'is_valid': True, 'issues':...</td>\n",
       "      <td>{'final_answer': 'The task \"Acme Corp ‚Äì initia...</td>\n",
       "      <td>{'argument_validity': 5, 'completeness': 5, 'e...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>48</td>\n",
       "      <td>company_directory</td>\n",
       "      <td>search_then_batch_delete_customers: Search for...</td>\n",
       "      <td>- **company_directory_find_email_address**: Fi...</td>\n",
       "      <td>[\n",
       "  {\n",
       "    \"type\": \"function\",\n",
       "    \"name\": \"com...</td>\n",
       "      <td>- **company_directory_find_email_address**: Fi...</td>\n",
       "      <td>Today's date is Thursday, 2026-01-29 and the c...</td>\n",
       "      <td>Could you pull the email addresses for everyon...</td>\n",
       "      <td>{'feasibility': 5, 'is_valid': True, 'issues':...</td>\n",
       "      <td>{'final_answer': 'Retrieved email addresses fo...</td>\n",
       "      <td>{'argument_validity': 5, 'completeness': 5, 'e...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>26</td>\n",
       "      <td>calendar</td>\n",
       "      <td>crm_to_email: Search CRM, then send emails to ...</td>\n",
       "      <td>- **company_directory_find_email_address**: Fi...</td>\n",
       "      <td>[\n",
       "  {\n",
       "    \"type\": \"function\",\n",
       "    \"name\": \"com...</td>\n",
       "      <td>- **company_directory_find_email_address**: Fi...</td>\n",
       "      <td>Today's date is Thursday, 2026-01-29 and the c...</td>\n",
       "      <td>Please find the meeting I have with Michael Le...</td>\n",
       "      <td>{'feasibility': 5, 'is_valid': True, 'issues':...</td>\n",
       "      <td>{'final_answer': 'The meeting with Michael Lee...</td>\n",
       "      <td>{'argument_validity': 5, 'completeness': 5, 'e...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   seed_id                       category  \\\n",
       "0       35  customer_relationship_manager   \n",
       "1       45                      analytics   \n",
       "2       46             project_management   \n",
       "3       48              company_directory   \n",
       "4       26                       calendar   \n",
       "\n",
       "                                             pattern  \\\n",
       "0  search_then_batch_delete_events: Search for ca...   \n",
       "1  get_task_info_then_update: Get specific task i...   \n",
       "2  lookup_then_add_customer: Look up a sales rep'...   \n",
       "3  search_then_batch_delete_customers: Search for...   \n",
       "4  crm_to_email: Search CRM, then send emails to ...   \n",
       "\n",
       "                                   tools_description  \\\n",
       "0  - **company_directory_find_email_address**: Fi...   \n",
       "1  - **company_directory_find_email_address**: Fi...   \n",
       "2  - **company_directory_find_email_address**: Fi...   \n",
       "3  - **company_directory_find_email_address**: Fi...   \n",
       "4  - **company_directory_find_email_address**: Fi...   \n",
       "\n",
       "                                          tools_json  \\\n",
       "0  [\n",
       "  {\n",
       "    \"type\": \"function\",\n",
       "    \"name\": \"com...   \n",
       "1  [\n",
       "  {\n",
       "    \"type\": \"function\",\n",
       "    \"name\": \"com...   \n",
       "2  [\n",
       "  {\n",
       "    \"type\": \"function\",\n",
       "    \"name\": \"com...   \n",
       "3  [\n",
       "  {\n",
       "    \"type\": \"function\",\n",
       "    \"name\": \"com...   \n",
       "4  [\n",
       "  {\n",
       "    \"type\": \"function\",\n",
       "    \"name\": \"com...   \n",
       "\n",
       "                                       tools_summary  \\\n",
       "0  - **company_directory_find_email_address**: Fi...   \n",
       "1  - **company_directory_find_email_address**: Fi...   \n",
       "2  - **company_directory_find_email_address**: Fi...   \n",
       "3  - **company_directory_find_email_address**: Fi...   \n",
       "4  - **company_directory_find_email_address**: Fi...   \n",
       "\n",
       "                                       system_prompt  \\\n",
       "0  Today's date is Thursday, 2026-01-29 and the c...   \n",
       "1  Today's date is Thursday, 2026-01-29 and the c...   \n",
       "2  Today's date is Thursday, 2026-01-29 and the c...   \n",
       "3  Today's date is Thursday, 2026-01-29 and the c...   \n",
       "4  Today's date is Thursday, 2026-01-29 and the c...   \n",
       "\n",
       "                                          user_query  \\\n",
       "0  Please delete all customers assigned to me (al...   \n",
       "1  Can you tell me how many website visits we had...   \n",
       "2  I need to add a follow‚Äëup task for our new cli...   \n",
       "3  Could you pull the email addresses for everyon...   \n",
       "4  Please find the meeting I have with Michael Le...   \n",
       "\n",
       "                                    user_query_judge  \\\n",
       "0  {'feasibility': 5, 'is_valid': True, 'issues':...   \n",
       "1  {'feasibility': 5, 'is_valid': True, 'issues':...   \n",
       "2  {'feasibility': 5, 'is_valid': True, 'issues':...   \n",
       "3  {'feasibility': 5, 'is_valid': True, 'issues':...   \n",
       "4  {'feasibility': 5, 'is_valid': True, 'issues':...   \n",
       "\n",
       "                                          trajectory  \\\n",
       "0  {'final_answer': 'All customers assigned to al...   \n",
       "1  {'final_answer': 'I have retrieved the total n...   \n",
       "2  {'final_answer': 'The task \"Acme Corp ‚Äì initia...   \n",
       "3  {'final_answer': 'Retrieved email addresses fo...   \n",
       "4  {'final_answer': 'The meeting with Michael Lee...   \n",
       "\n",
       "                                    trajectory_judge  \n",
       "0  {'argument_validity': 5, 'completeness': 3, 'e...  \n",
       "1  {'argument_validity': 5, 'completeness': 3, 'e...  \n",
       "2  {'argument_validity': 5, 'completeness': 5, 'e...  \n",
       "3  {'argument_validity': 5, 'completeness': 5, 'e...  \n",
       "4  {'argument_validity': 5, 'completeness': 5, 'e...  "
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from functools import partial\n",
    "from utils import convert_to_nemo_gym_format, save_for_nemo_gym\n",
    "\n",
    "convert_fn = partial(convert_to_nemo_gym_format, tools=TOOLS, system_prompt=SYSTEM_PROMPT)\n",
    "\n",
    "output_path = \"workplace_assistant_train-gpt-oss.jsonl\"\n",
    "save_for_nemo_gym(filtered_df, output_path, convert_fn=convert_fn)\n",
    "\n",
    "print(\"\\nSample generated data (passed both quality stages):\")\n",
    "filtered_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary\n",
    "\n",
    "This notebook demonstrated how to build a complete synthetic data generation pipeline for multi-step tool-calling tasks using **Data Designer**. The pipeline generates user queries, simulates agent trajectories, and applies dual-level LLM judge filtering to produce high-quality training data.\n",
    "\n",
    "## Next Steps\n",
    "\n",
    "- **Scale up generation**: Increase `num_seeds` and `num_records` to produce larger training sets (1,000+ examples)\n",
    "- **Customize for your domain**: Replace the Workplace Assistant tools with your own tool definitions\n",
    "- **Add more multi-step patterns**: Define new patterns in `environment.json` to increase task diversity\n",
    "- **Tune judge thresholds**: Inspect rejected examples with `show_rejection_reasons()` and adjust filtering thresholds\n",
    "- **Train with NeMo Gym and NeMo RL**: Use the exported JSONL file for GRPO training with NeMo RL, using a NeMo Gym environment."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
